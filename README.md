# TwinDNN

TwinDNN system pairs a high-accuracy heavy-duty network with a low-latency light-weight (e.g., highly compressed) network using a hierarchical inference logic that will infer high-accuracy network when the prediction of low-latency network is not considered confident. TwinDNN can recover up to 94% of accuracy drop caused by extreme network compression, with more than 90% speedup compared to just using the original heavy-duty DNN.

Copyright (c) <2021>

<University of Illinois at Urbana-Champaign>

All rights reserved.

Developed by:

<http://dchen.ece.illinois.edu >

<University of Illinois at Urbana-Champaign>
  
This open source project contains the source code for TwinDNN. 
  
When referencing this application in a publication, please cite the following paper:

[1] H. Jeong and D. Chen, "TwinDNN: A Tale of Two Deep Neural Networks," IEEE International Conference on Application-specific Systems, Architectures and Processors, 2021. 
